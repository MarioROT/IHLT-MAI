{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarioROT/IHLT-MAI/blob/main/Session3_MarioRosas_AlamLopez.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpEp-jhafvsx"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "```\n",
        "\n",
        "# Lab session 3 (Morphology) - IHLT\n",
        "\n",
        "**Students:**\n",
        "- Mario Rosas\n",
        "- Alam Lopez\n",
        "\n",
        "**Lab Professor:** Salvador Medina Herrera"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0LXucmalIYk"
      },
      "source": [
        "## Paraphrases Template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yeQ11CQB4e3o",
        "outputId": "f9f1bcb8-7b49-46f8-d3da-6e98909756af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'IHLT-MAI'...\n",
            "remote: Enumerating objects: 93, done.\u001b[K\n",
            "remote: Counting objects: 100% (93/93), done.\u001b[K\n",
            "remote: Compressing objects: 100% (80/80), done.\u001b[K\n",
            "remote: Total 93 (delta 44), reused 44 (delta 12), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (93/93), 144.38 KiB | 3.52 MiB/s, done.\n",
            "Resolving deltas: 100% (44/44), done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "%%shell\n",
        "git clone https://github.com/mariorot/IHLT-MAI.git\n",
        "cd 'IHLT-MAI'\n",
        "mv 'complementary_material' /content/\n",
        "mv scripts /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Mi9UgnrHx1NN",
        "outputId": "d0476f33-aed6-4440-82ea-3a711c1b4fa7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "from scripts.compute_metrics import ComputeMetrics\n",
        "from scripts.text_preprocessing import TextPreprocessing\n",
        "import pandas as pd\n",
        "from scipy.stats import pearsonr\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "import string\n",
        "import collections\n",
        "from nltk.text import Text\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fx90zvqXx5eA"
      },
      "outputs": [],
      "source": [
        "dt = pd.read_csv('complementary_material/test-gold/STS.input.SMTeuroparl.txt',sep='\\t',header=None)\n",
        "dt['gs'] = pd.read_csv('complementary_material/test-gold/STS.gs.SMTeuroparl.txt',sep='\\t',header=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HHcaJhckB_Q"
      },
      "source": [
        "## TODO\n",
        "1. Read all pairs of sentences of the SMTeuroparl files of test set within the evaluation framework of the project. Compute their similarities by considering *lemmas* and *Jaccard distance*. <br>\n",
        "\n",
        "2. Compare the results with those in session 2 (document structure) in which words were considered. : <br>\n",
        "\n",
        "3. Compare the results with gold standard by giving the pearson correlation between them. <br>\n",
        "\n",
        "4. Questions (justify the answers): <br>\n",
        "\n",
        "      Which is better: words or lemmas?\n",
        "\n",
        "      Do you think that could perform better for any pair of texts?\n",
        "```\n",
        "from scipy.stats import pearsonr\n",
        "pearsonr(dt['gs'], dt['jaccard'])[0]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_corpus(corpus, stopwords, minwords_len, signs):\n",
        "   corpus = [word.lower() for word in corpus]\n",
        "   corpus = [word for word in corpus if word not in stopwords]\n",
        "   corpus = [word for word in corpus if len(word) > minwords_len]\n",
        "   corpus = [word for word in corpus if not any(caracter in signs for caracter in word)]\n",
        "   return corpus"
      ],
      "metadata": {
        "id": "g2apqgKX9VdR"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus1 = dt[0]\n",
        "corpus2 = dt[1]\n",
        "stopwords=set(nltk.corpus.stopwords.words('english'))\n",
        "signs = string.punctuation\n",
        "minwords_len = 2\n",
        "corpus1.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkcrqwja9-Mn",
        "outputId": "39fabf57-bcef-45af-acca-6374c1581867"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    The leaders have now been given a new chance a...\n",
              "1    Amendment No 7 proposes certain changes in the...\n",
              "2    Let me remind you that our allies include ferv...\n",
              "3          The vote will take place today at 5.30 p.m.\n",
              "4    The fishermen are inactive, tired and disappoi...\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " dt[100]=clean_corpus(dt.iloc[0,0],stopwords,minwords_len, signs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "VtRT_gXlF9Ve",
        "outputId": "796b923f-3eac-4856-ee99-83a404ea119b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-3e9e1ee8641e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclean_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mminwords_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3978\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3979\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3980\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3982\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4172\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4173\u001b[0m         \"\"\"\n\u001b[0;32m-> 4174\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4176\u001b[0m         if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4914\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4915\u001b[0;31m             \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4916\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    569\u001b[0m     \"\"\"\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    572\u001b[0m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Length of values (0) does not match length of index (459)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " dt[2]=clean_corpus(corpus1,stopwords,minwords_len, signs)\n",
        " dt[3]=clean_corpus(corpus2,stopwords,minwords_len, signs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "4rtq6CjC_Kqp",
        "outputId": "aaea4a26-fd35-4759-efac-b09468ec0089"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-6e91d6de9029>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclean_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mminwords_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclean_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mminwords_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3978\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3979\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3980\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3982\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4172\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4173\u001b[0m         \"\"\"\n\u001b[0;32m-> 4174\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4176\u001b[0m         if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4914\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4915\u001b[0;31m             \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4916\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    569\u001b[0m     \"\"\"\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    572\u001b[0m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Length of values (17) does not match length of index (459)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code for the tokenization is at: https://github.com/MarioROT/IHLT-MAI/blob/main/scripts/text_preprocessing.py\n",
        "\n",
        "The code for jaccard distance computation is at: https://github.com/MarioROT/IHLT-MAI/blob/main/scripts/compute_metrics.py"
      ],
      "metadata": {
        "id": "1Zbp3bhp5gWC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "M-brR3HYWunv",
        "outputId": "797be9e3-0558-4646-dea7-041c0915caa7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing jaccard...\n",
            "Computing jaccard...\n"
          ]
        }
      ],
      "source": [
        "tp = TextPreprocessing()\n",
        "dt[4] = tp.tokenize_data(list(dt[0]),'nltk')\n",
        "dt[5] = tp.tokenize_data(list(dt[1]),'nltk')\n",
        "cm_nltk = ComputeMetrics(dt[[4,5]].to_numpy(), ['jaccard'], 1)\n",
        "dt['jaccard_token_nltk'] = cm_nltk.do()['jaccard']\n",
        "\n",
        "dt[6] = tp.tokenize_data(list(dt[2]),'nltk')\n",
        "dt[7] = tp.tokenize_data(list(dt[3]),'nltk')\n",
        "cm_clean_nltk = ComputeMetrics(dt[[6,7]].to_numpy(), ['jaccard'], 1)\n",
        "dt['jaccard_token_clean_nltk'] = cm_clean_nltk.do()['jaccard']\n",
        "\n",
        "\n",
        "dt[8] = tp.tokenize_data(list(dt[0]),'spacy')\n",
        "dt[9] = tp.tokenize_data(list(dt[1]),'spacy')\n",
        "cm_spacy = ComputeMetrics(dt[[8,9]].to_numpy(), ['jaccard'], 1)\n",
        "dt['jaccard_token_spacy'] = cm_spacy.do()['jaccard']\n",
        "\n",
        "\n",
        "dt[10] = tp.tokenize_data(list(dt[2]),'spacy')\n",
        "dt[11] = tp.tokenize_data(list(dt[3]),'spacy')\n",
        "cm_clean_spacy = ComputeMetrics(dt[[10,11]].to_numpy(), ['jaccard'], 1)\n",
        "dt['jaccard_token_clean_spacy'] = cm_clean_spacy.do()['jaccard']\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt[12]=tp.lemmatize_data(list(dt[0]),'spacy')\n",
        "dt[13]=tp.lemmatize_data(list(dt[1]),'spacy')\n",
        "cm_lemma_spacy = ComputeMetrics(dt[[12,13]].to_numpy(), ['jaccard'], 1)\n",
        "dt['jaccard_lemma_spacy']=cm_lemma_spacy.do()['jaccard']\n",
        "\n",
        "dt[14]=tp.lemmatize_data(list(dt[2]),'spacy')\n",
        "dt[15]=tp.lemmatize_data(list(dt[3]),'spacy')\n",
        "cm_lemma_clean_spacy = ComputeMetrics(dt[[14,15]].to_numpy(), ['jaccard'], 1)\n",
        "dt['jaccard_lemma_clean_spacy']=cm_lemma_clean_spacy.do()['jaccard']\n",
        "\n",
        "dt[16]=tp.lemmatize_data(list(dt[0]),'nltk')\n",
        "dt[17]=tp.lemmatize_data(list(dt[1]),'nltk')\n",
        "cm_lemma_nltk = ComputeMetrics(dt[[16,17]].to_numpy(), ['jaccard'], 1)\n",
        "dt['jaccard_lemma_nltk']=cm_lemma_nltk.do()['jaccard']\n",
        "\n",
        "dt[18]=tp.lemmatize_data(list(dt[2]),'nltk')\n",
        "dt[19]=tp.lemmatize_data(list(dt[3]),'nltk')\n",
        "cm_lemma_clean_nltk = ComputeMetrics(dt[[18,19]].to_numpy(), ['jaccard'], 1)\n",
        "dt['jaccard_lemma_clean_nltk']=cm_lemma_clean_nltk.do()['jaccard']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_gOj3wb5Lrr",
        "outputId": "f771e0d4-782d-429f-c03b-95b6d5a8dcdc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing jaccard...\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Applying NLTK tokenization to the sentence\n",
            "Computing jaccard...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "HAjyT-miWunw",
        "outputId": "e2aec248-3303-4f65-c4c1-79e663aa2063",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        gs  jaccard_token_nltk  jaccard_token_spacy  jaccard_lemma_nltk  \\\n",
              "0    4.500            0.653846             0.653846            0.653846   \n",
              "1    5.000            0.214286             0.214286            0.076923   \n",
              "2    4.250            0.608696             0.608696            0.608696   \n",
              "3    4.500            0.454545             0.400000            0.454545   \n",
              "4    5.000            0.000000             0.000000            0.000000   \n",
              "..     ...                 ...                  ...                 ...   \n",
              "454  5.000            0.450000             0.450000            0.450000   \n",
              "455  4.750            0.642857             0.714286            0.642857   \n",
              "456  5.000            0.600000             0.600000            0.600000   \n",
              "457  4.000            0.681818             0.681818            0.681818   \n",
              "458  3.833            0.500000             0.500000            0.500000   \n",
              "\n",
              "     jaccard_lemma_spacy  \n",
              "0               0.600000  \n",
              "1               0.076923  \n",
              "2               0.545455  \n",
              "3               0.400000  \n",
              "4               0.000000  \n",
              "..                   ...  \n",
              "454             0.450000  \n",
              "455             0.615385  \n",
              "456             0.526316  \n",
              "457             0.619048  \n",
              "458             0.500000  \n",
              "\n",
              "[459 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f5096418-c0bb-4786-a4ae-a85a2f61e0fc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gs</th>\n",
              "      <th>jaccard_token_nltk</th>\n",
              "      <th>jaccard_token_spacy</th>\n",
              "      <th>jaccard_lemma_nltk</th>\n",
              "      <th>jaccard_lemma_spacy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.500</td>\n",
              "      <td>0.653846</td>\n",
              "      <td>0.653846</td>\n",
              "      <td>0.653846</td>\n",
              "      <td>0.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.000</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>0.076923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.250</td>\n",
              "      <td>0.608696</td>\n",
              "      <td>0.608696</td>\n",
              "      <td>0.608696</td>\n",
              "      <td>0.545455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.500</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>454</th>\n",
              "      <td>5.000</td>\n",
              "      <td>0.450000</td>\n",
              "      <td>0.450000</td>\n",
              "      <td>0.450000</td>\n",
              "      <td>0.450000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>455</th>\n",
              "      <td>4.750</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.615385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456</th>\n",
              "      <td>5.000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.526316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>457</th>\n",
              "      <td>4.000</td>\n",
              "      <td>0.681818</td>\n",
              "      <td>0.681818</td>\n",
              "      <td>0.681818</td>\n",
              "      <td>0.619048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>458</th>\n",
              "      <td>3.833</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>459 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5096418-c0bb-4786-a4ae-a85a2f61e0fc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f5096418-c0bb-4786-a4ae-a85a2f61e0fc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f5096418-c0bb-4786-a4ae-a85a2f61e0fc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4298a081-6efa-430b-97ca-fe2a1dfb6d14\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4298a081-6efa-430b-97ca-fe2a1dfb6d14')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4298a081-6efa-430b-97ca-fe2a1dfb6d14 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "dt[['gs','jaccard_token_nltk','jaccard_token_clean_nltk','jaccard_token_spacy','jaccard_token_clean_spacy','jaccard_lemma_nltk','jaccard_lemma_clean_nltk','jaccard_lemma_spacy','jaccard_lemma_clean_spacy']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0LVZunA82f2",
        "outputId": "0069d0c2-7ba4-4603-f34d-f1de0d18838e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK 0.45049771693186846 --- spaCy 0.4608504322255335\n"
          ]
        }
      ],
      "source": [
        "p_token_nltk=pearsonr(dt['gs'], 1-dt['jaccard_token_nltk'])[0] # Calculating the pearson correlation between GS results and 1-Jaccard calculated dats\n",
        "p_token_nltk_clean=pearsonr(dt['gs'], 1-dt['jaccard_token_clean_nltk'])[0]\n",
        "p_token_spacy=pearsonr(dt['gs'], 1-dt['jaccard_token_spacy'])[0]\n",
        "p_token_spacy_clean=pearsonr(dt['gs'], 1-dt['jaccard_token_clean_spacy'])[0]\n",
        "p_lemma_nltk=pearsonr(dt['gs'], 1-dt['jaccard_lemma_nltk'])[0] # Calculating the pearson correlation between GS results and 1-Jaccard calculated dats\n",
        "p_lemma_nltk_clean=pearsonr(dt['gs'], 1-dt['jaccard_lemma_clean_nltk'])[0]\n",
        "p_lemma_spacy=pearsonr(dt['gs'], 1-dt['jaccard_lemma_spacy'])[0]\n",
        "p_lemma_spacy_clean=pearsonr(dt['gs'], 1-dt['jaccard_lemma_clean_spacy'])[0]\n",
        "\n",
        "\n",
        "print(f'Token:  NLTK {p_token_nltk} --- NLTK clean {p_token_nltk_clean} --- spaCy {p_token_spacy} --- spaCy clean {p_token_spacy_clean}')\n",
        "print(f'Lemma:  NLTK {p_lemma_nltk} --- NLTK clean {p_lemma_nltk_clean} --- spaCy {p_lemma_spacy} --- spaCy clean {p_lemma_spacy_clean}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjCFQFyeeO28"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "Which is better: words or lemmas?\n",
        "\n",
        "Do you think that could perform better for any pair of texts?\n",
        "\n",
        "\n",
        "The use of different tokenizers (NLTK and spaCy) can impact the results when comparing sentence pairs, as they may perform differently depending on the input text data. Jaccard similarity proved to be an effective metric for comparing the similarity of sentence pairs after word tokenization. With the inversion of this metric we got a distance to measure the dissimilarity between sets of tokens, making it suitable for the task we were trying to solve. The Pearson correlation coefficient provided us a quantitative measure of how well our results align with the gold-standard, i.e. effectiveness.\n",
        "\n",
        "The results indicate that spaCy slightly outperformed NLTK in the task of sentence pair comparison using Jaccard distance.The Pearson correlation coefficient values obtained for **NLTK (0.4505)** and **spaCy (0.4609)** suggest a moderate positive correlation between the computed distances and the benchmark (gold-standard) distances.\n",
        "\n",
        "Our best result could be possibly improved by experimenting with different tokenization strategies or exploring other NLP techniques to enhance the performance.\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "IHLT",
      "language": "python",
      "name": "ihlt"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "0795eca24a98e58b2dcbec80c9554a91f94c5c7d4e675f06c8c2f85c434623a5"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}