{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarioROT/IHLT-MAI/blob/main/Session8_MarioRosas_AlamLopez.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpEp-jhafvsx"
      },
      "source": [
        "# Lab session 8 (Syntactic Parser) - IHLT\n",
        "\n",
        "**Students:**\n",
        "- Mario Rosas\n",
        "- Alam Lopez\n",
        "\n",
        "**Lab Professor:** Salvador Medina Herrera"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0LXucmalIYk"
      },
      "source": [
        "## Paraphrases Template"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "git clone https://github.com/mariorot/IHLT-MAI.git\n",
        "cd 'IHLT-MAI'\n",
        "mv 'complementary_material' /content/\n",
        "mv scripts /content/\n"
      ],
      "metadata": {
        "id": "BmIHkibRWPJB",
        "outputId": "0536d3c5-21d5-4113-b895-cf39672c5013",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'IHLT-MAI'...\n",
            "remote: Enumerating objects: 393, done.\u001b[K\n",
            "remote: Counting objects: 100% (203/203), done.\u001b[K\n",
            "remote: Compressing objects: 100% (150/150), done.\u001b[K\n",
            "remote: Total 393 (delta 139), reused 89 (delta 53), pack-reused 190\u001b[K\n",
            "Receiving objects: 100% (393/393), 327.88 KiB | 4.82 MiB/s, done.\n",
            "Resolving deltas: 100% (229/229), done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "rsUmxQSSWefg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scripts.text_preprocessing import TextPreprocessing\n",
        "from complementary_material.textserver import TextServer\n",
        "import nltk\n",
        "from nltk import CFG, ChartParser\n",
        "!pip install svgling\n",
        "import svgling\n"
      ],
      "metadata": {
        "id": "ZUbLSXbZWrbD",
        "outputId": "bc65cc94-1a09-415e-f5f3-29eeda218192",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: svgling in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: svgwrite in /usr/local/lib/python3.10/dist-packages (from svgling) (1.4.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO\n",
        "\n",
        "- Consider the following sentence: **Lazy cats play with mice.**\n",
        "\n",
        "- Expand the grammar of the example related to non-probabilistic chart parsers in order to subsume this new sentence.\n",
        "\n",
        "- Perform the constituency parsing using a BottomUpChartParser, a BottomUpLeftCornerChartParser and a LeftCornerChartParser.\n",
        "\n",
        "- For each one of them, provide the resulting tree, the number of edges and the list of explored edges.\n",
        "\n",
        "- Which parser is the most efficient for parsing the sentence?\n",
        "\n",
        "- Which edges are filtered out by each parser and why?"
      ],
      "metadata": {
        "id": "xAYq3TUOVrIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "phrase=\"Lazy cats play with mice.\"\n",
        "test_sentence=\"Lazy cats and mice.\""
      ],
      "metadata": {
        "id": "-SuM3JKeVJAv"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tp = TextPreprocessing()\n",
        "\n",
        "clean_sentence=tp.clean_sentence(phrase, signs=True)"
      ],
      "metadata": {
        "id": "kgCuFSI64Io8",
        "outputId": "0a4d89e3-09e7-4554-8ceb-5b6c7a3f2c32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-82e47fb222b5>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextPreprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclean_sentence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/scripts/text_preprocessing.py\u001b[0m in \u001b[0;36mclean_sentence\u001b[0;34m(self, sentence, lowercase, stopwords, minwords_len, signs)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msigns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaracter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msigns\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcaracter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_signs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopwords\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misalpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/scripts/text_preprocessing.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msigns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaracter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msigns\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcaracter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_signs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopwords\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misalpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/scripts/text_preprocessing.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msigns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaracter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msigns\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcaracter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_signs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopwords\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misalpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: argument of type 'bool' is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_sentence"
      ],
      "metadata": {
        "id": "flWtMaI64xx5",
        "outputId": "b01957ac-1c02-4179-a07d-8599ea0ea61a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['lazy', 'cats', 'play', 'with', 'mice.']"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_to_cfg(sentence):\n",
        "    words = nltk.word_tokenize(sentence)\n",
        "    pos_tags = nltk.pos_tag(words)\n",
        "\n",
        "    productions = []\n",
        "\n",
        "    for i in range(len(pos_tags)):\n",
        "        productions.append(f\"Word_{i} -> '{words[i]}'\")\n",
        "        productions.append(f\"POS_{i} -> '{pos_tags[i][1]}'\")\n",
        "\n",
        "    for i in range(len(pos_tags) - 1):\n",
        "        productions.append(f\"Phrase_{i} -> Word_{i} | POS_{i}\")\n",
        "        productions.append(f\"Sentence -> Phrase_{i} Phrase_{i+1}\")\n",
        "\n",
        "    cfg_string = \"\\n\".join(productions)\n",
        "\n",
        "    return CFG.fromstring(cfg_string)\n",
        "\n",
        "# Example sentence\n",
        "sentence = \"The cat chased the mouse\"\n",
        "\n",
        "# Convert sentence to CFG\n",
        "cfg = sentence_to_cfg(sentence)\n",
        "\n",
        "# Print the CFG\n",
        "print(cfg)"
      ],
      "metadata": {
        "id": "Ka9SKA7NRHEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grammar = CFG.fromstring(\"\"\"\n",
        "    S -> NP VP\n",
        "    NP -> Adj N | N\n",
        "    VP -> V NP\n",
        "    Adj -> 'Lazy'\n",
        "    N -> 'cats' | 'mice'\n",
        "    V -> 'play' | 'with'\n",
        "\"\"\") #added manually, shall we create a function to obtain it?\n",
        "\n",
        "  #Do we need to first pass everything to chomsky normal form?\n",
        "\n",
        "\n",
        "parser = ChartParser(grammar, trace=1)\n",
        "parse = parser.chart_parse(clean_test_sentence)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xa23M2DBLDKw",
        "outputId": "6fdab2ad-f1c0-4f19-b61d-7c038fd5d175",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|.  small  .   cats  .   and   .   mice  .|\n",
            "|[---------]         .         .         .| [0:1] 'small'\n",
            "|.         [---------]         .         .| [1:2] 'cats'\n",
            "|.         .         [---------]         .| [2:3] 'and'\n",
            "|.         .         .         [---------]| [3:4] 'mice'\n",
            "|[---------]         .         .         .| [0:1] JJ -> 'small' *\n",
            "|[--------->         .         .         .| [0:1] NP -> JJ * NNS\n",
            "|.         [---------]         .         .| [1:2] NNS -> 'cats' *\n",
            "|.         [---------]         .         .| [1:2] NP -> NNS *\n",
            "|.         [--------->         .         .| [1:2] NNS -> NNS * CC NNS\n",
            "|[-------------------]         .         .| [0:2] NP -> JJ NNS *\n",
            "|[------------------->         .         .| [0:2] NP -> NP * CC NP\n",
            "|.         [--------->         .         .| [1:2] NP -> NP * CC NP\n",
            "|.         .         [---------]         .| [2:3] CC -> 'and' *\n",
            "|.         [------------------->         .| [1:3] NNS -> NNS CC * NNS\n",
            "|[----------------------------->         .| [0:3] NP -> NP CC * NP\n",
            "|.         [------------------->         .| [1:3] NP -> NP CC * NP\n",
            "|.         .         .         [---------]| [3:4] NNS -> 'mice' *\n",
            "|.         .         .         [---------]| [3:4] NP -> NNS *\n",
            "|.         .         .         [--------->| [3:4] NNS -> NNS * CC NNS\n",
            "|.         [-----------------------------]| [1:4] NNS -> NNS CC NNS *\n",
            "|.         [-----------------------------]| [1:4] NP -> NNS *\n",
            "|.         [----------------------------->| [1:4] NNS -> NNS * CC NNS\n",
            "|[=======================================]| [0:4] NP -> JJ NNS *\n",
            "|[--------------------------------------->| [0:4] NP -> NP * CC NP\n",
            "|.         [----------------------------->| [1:4] NP -> NP * CC NP\n",
            "|.         .         .         [--------->| [3:4] NP -> NP * CC NP\n",
            "|[=======================================]| [0:4] NP -> NP CC NP *\n",
            "|.         [-----------------------------]| [1:4] NP -> NP CC NP *\n",
            "|.         [----------------------------->| [1:4] NP -> NP * CC NP\n",
            "|[--------------------------------------->| [0:4] NP -> NP * CC NP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Total edges: {parse.num_edges()}\\n')\n",
        "parse.edges()\n",
        "#Do we need to add the main sentence?  S -> 'small cats and mice'"
      ],
      "metadata": {
        "id": "XIGLmYwULJsr",
        "outputId": "4ee5846a-4cf0-4b9d-fa93-c676e0262db4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total edges: 28\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[Edge: [0:1] 'small'],\n",
              " [Edge: [1:2] 'cats'],\n",
              " [Edge: [2:3] 'and'],\n",
              " [Edge: [3:4] 'mice'],\n",
              " [Edge: [0:1] JJ -> 'small' *],\n",
              " [Edge: [0:1] NP -> JJ * NNS],\n",
              " [Edge: [1:2] NNS -> 'cats' *],\n",
              " [Edge: [1:2] NP -> NNS *],\n",
              " [Edge: [1:2] NNS -> NNS * CC NNS],\n",
              " [Edge: [0:2] NP -> JJ NNS *],\n",
              " [Edge: [0:2] NP -> NP * CC NP],\n",
              " [Edge: [1:2] NP -> NP * CC NP],\n",
              " [Edge: [2:3] CC -> 'and' *],\n",
              " [Edge: [1:3] NNS -> NNS CC * NNS],\n",
              " [Edge: [0:3] NP -> NP CC * NP],\n",
              " [Edge: [1:3] NP -> NP CC * NP],\n",
              " [Edge: [3:4] NNS -> 'mice' *],\n",
              " [Edge: [3:4] NP -> NNS *],\n",
              " [Edge: [3:4] NNS -> NNS * CC NNS],\n",
              " [Edge: [1:4] NNS -> NNS CC NNS *],\n",
              " [Edge: [1:4] NP -> NNS *],\n",
              " [Edge: [1:4] NNS -> NNS * CC NNS],\n",
              " [Edge: [0:4] NP -> JJ NNS *],\n",
              " [Edge: [0:4] NP -> NP * CC NP],\n",
              " [Edge: [1:4] NP -> NP * CC NP],\n",
              " [Edge: [3:4] NP -> NP * CC NP],\n",
              " [Edge: [0:4] NP -> NP CC NP *],\n",
              " [Edge: [1:4] NP -> NP CC NP *]]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ts = list(parse)\n",
        "'{num} trees.'.format(num=len(ts))"
      ],
      "metadata": {
        "id": "hpGh7TvpuO5a",
        "outputId": "bcc6d3e4-dda4-488c-d087-a6437a848d4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'28 trees.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ts[0])"
      ],
      "metadata": {
        "id": "OU0UHIROLUII",
        "outputId": "9bf4f9c5-9971-4123-b32d-aa646f531890",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0:1] 'small'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ts[0]"
      ],
      "metadata": {
        "id": "cMsJEveBLbwK",
        "outputId": "be42fb20-7df0-4de1-bbc6-6f08bc4d1a27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Edge: [0:1] 'small']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ts[1]"
      ],
      "metadata": {
        "id": "6p1vDV-1LdMv",
        "outputId": "1f20646d-afd8-4485-e600-83a0b9f675d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Edge: [1:2] 'cats']"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import TopDownChartParser\n",
        "parser = nltk.TopDownChartParser(grammar)\n",
        "parse = parser.parse(sent)"
      ],
      "metadata": {
        "id": "dpCmqrDuLmTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import CFG\n",
        "\n",
        "def sentence_to_cfg(sentence):\n",
        "    words = nltk.word_tokenize(sentence)\n",
        "    pos_tags = nltk.pos_tag(words)\n",
        "\n",
        "    productions = []\n",
        "\n",
        "    for i in range(len(pos_tags)):\n",
        "        productions.append(f\"Word_{i} -> '{words[i]}'\")\n",
        "        productions.append(f\"POS_{i} -> '{pos_tags[i][1]}'\")\n",
        "\n",
        "    for i in range(len(pos_tags) - 1):\n",
        "        productions.append(f\"Phrase_{i} -> Word_{i} | POS_{i}\")\n",
        "        productions.append(f\"Sentence -> Phrase_{i} Phrase_{i+1}\")\n",
        "\n",
        "    cfg_string = \"\\n\".join(productions)\n",
        "\n",
        "    return CFG.fromstring(cfg_string)\n",
        "\n",
        "# Example sentence\n",
        "sentence = \"The cat chased the mouse\"\n",
        "\n",
        "# Convert sentence to CFG\n",
        "cfg = sentence_to_cfg(sentence)\n",
        "\n",
        "# Print the CFG\n",
        "print(cfg)"
      ],
      "metadata": {
        "id": "C2fqZsTzytW1",
        "outputId": "213876eb-895d-4114-eef4-d5b79f653295",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grammar with 22 productions (start state = Word_0)\n",
            "    Word_0 -> 'The'\n",
            "    POS_0 -> 'DT'\n",
            "    Word_1 -> 'cat'\n",
            "    POS_1 -> 'NN'\n",
            "    Word_2 -> 'chased'\n",
            "    POS_2 -> 'VBD'\n",
            "    Word_3 -> 'the'\n",
            "    POS_3 -> 'DT'\n",
            "    Word_4 -> 'mouse'\n",
            "    POS_4 -> 'NN'\n",
            "    Phrase_0 -> Word_0\n",
            "    Phrase_0 -> POS_0\n",
            "    Sentence -> Phrase_0 Phrase_1\n",
            "    Phrase_1 -> Word_1\n",
            "    Phrase_1 -> POS_1\n",
            "    Sentence -> Phrase_1 Phrase_2\n",
            "    Phrase_2 -> Word_2\n",
            "    Phrase_2 -> POS_2\n",
            "    Sentence -> Phrase_2 Phrase_3\n",
            "    Phrase_3 -> Word_3\n",
            "    Phrase_3 -> POS_3\n",
            "    Sentence -> Phrase_3 Phrase_4\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "IHLT",
      "language": "python",
      "name": "ihlt"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "0795eca24a98e58b2dcbec80c9554a91f94c5c7d4e675f06c8c2f85c434623a5"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}